<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Speech-to-Speech Translation ¬∑ 50 Languages</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, sans-serif;
      background: #0f172a;
      color: #e5e7eb;
      display: flex;
      justify-content: center;
      padding: 2rem;
    }

    .app {
      max-width: 520px;
      width: 100%;
      background: #020617;
      border-radius: 14px;
      padding: 1.75rem;
      box-shadow: 0 20px 40px rgba(0,0,0,0.45);
    }

    h1 {
      font-size: 1.35rem;
      margin-bottom: 0.25rem;
    }

    .subtitle {
      font-size: 0.9rem;
      color: #94a3b8;
      margin-bottom: 1rem;
    }

    select, button {
      width: 100%;
      padding: 0.75rem;
      margin-top: 0.75rem;
      border-radius: 10px;
      border: none;
      font-size: 1rem;
    }

    select {
      background: #020617;
      color: #e5e7eb;
      border: 1px solid #334155;
    }

    button {
      background: #4f46e5;
      color: white;
      cursor: pointer;
      font-weight: 500;
    }

    button.recording {
      background: #dc2626;
    }

    .status {
      margin-top: 0.75rem;
      font-size: 0.85rem;
      color: #94a3b8;
    }

    .output {
      margin-top: 1.25rem;
      background: #020617;
      border: 1px solid #334155;
      border-radius: 10px;
      padding: 0.9rem;
      font-size: 0.85rem;
      white-space: pre-wrap;
      line-height: 1.45;
    }

    audio {
      margin-top: 1rem;
      width: 100%;
    }

    footer {
      margin-top: 1.25rem;
      font-size: 0.75rem;
      color: #64748b;
      text-align: center;
    }
  </style>
</head>

<body>
  <div class="app">
    <h1>üó£Ô∏è Speech-to-Speech Translator</h1>
    <div class="subtitle">
      Whisper ‚Üí mBART-50 ‚Üí gTTS ¬∑ 50 languages
    </div>

    <select id="language">
      <option value="en">English</option>
      <option value="es">Spanish</option>
      <option value="fr">French</option>
      <option value="de">German</option>
      <option value="it">Italian</option>
      <option value="pt">Portuguese</option>
      <option value="ru">Russian</option>
      <option value="ar">Arabic</option>
      <option value="hi">Hindi</option>
      <option value="zh">Chinese</option>
      <option value="ja">Japanese</option>
      <option value="ko">Korean</option>
      <option value="vi">Vietnamese</option>
      <option value="tr">Turkish</option>
      <option value="pl">Polish</option>
    </select>

    <button id="recordBtn">Start Recording</button>
    <div class="status" id="status">Idle</div>

    <div class="output" id="textOutput"></div>
    <audio id="audioOutput" controls></audio>

    <footer>
      Powered by Hugging Face Spaces ¬∑ Public demo
    </footer>
  </div>

  <!-- ‚úÖ Gradio Client (browser-safe) -->
  <script type="module">
    import { Client } from "https://cdn.jsdelivr.net/npm/@gradio/client/+esm";

    const SPACE_NAME =
      "Jchamo/speech-to-speech-translation-50-languages";

    const recordBtn = document.getElementById("recordBtn");
    const statusEl = document.getElementById("status");
    const textOutput = document.getElementById("textOutput");
    const audioOutput = document.getElementById("audioOutput");
    const languageSelect = document.getElementById("language");

    let app;
    let mediaRecorder;
    let audioChunks = [];
    let recording = false;

    statusEl.textContent = "Connecting to Hugging Face Space‚Ä¶";

    app = await Client.connect(SPACE_NAME);

    statusEl.textContent = "Ready";

    recordBtn.onclick = async () => {
      if (!recording) {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        audioChunks = [];

        mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
        mediaRecorder.onstop = runInference;

        mediaRecorder.start();
        recording = true;
        recordBtn.textContent = "Stop Recording";
        recordBtn.classList.add("recording");
        statusEl.textContent = "Recording‚Ä¶";
      } else {
        mediaRecorder.stop();
        recording = false;
        recordBtn.textContent = "Start Recording";
        recordBtn.classList.remove("recording");
        statusEl.textContent = "Processing‚Ä¶";
      }
    };

    async function runInference() {
      const audioBlob = new Blob(audioChunks, { type: "audio/webm" });

      const result = await app.predict("/predict", [
        audioBlob,
        languageSelect.value
      ]);

      const [transcription, translation, audioFile] = result.data;

      textOutput.textContent =
        `Transcription:\n${transcription}\n\nTranslation:\n${translation}`;

      audioOutput.src = audioFile;
      audioOutput.play();

      statusEl.textContent = "Done";
    }
  </script>
</body>
</html>
